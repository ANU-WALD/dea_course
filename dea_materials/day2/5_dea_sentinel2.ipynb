{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel-2\n",
    "\n",
    "#### Sentinel-2 is an Earth observation mission from the EU Copernicus Programme that systematically acquires optical imagery at high spatial resolution (up to 10 m for some bands). The mission is based on a constellation of two identical satellites in the same orbit, 180Â° apart for optimal coverage and data delivery. Together, they cover all Earth's land surfaces, large islands, inland and coastal waters every 3-5 days.\n",
    "\n",
    "#### Sentinel-2A was launched on 23 June 2015 and Sentinel-2B followed on 7 March 2017. Both of the Sentinel-2 satellites carry an innovative wide swath high-resolution multispectral imager with 13 spectral bands. For more information on the Sentinel-2 platforms and applications, check out the [European Space Agency website](http://www.esa.int/Applications/Observing_the_Earth/Copernicus/Overview4).\n",
    "\n",
    "#### Digital Earth Australia (DEA) applies corrections to Sentinel-2 satellite images to arrive at a [surface reflectance](https://cmi.ga.gov.au/ga_s2_m_nbart_1) product (see the [introduction to Digtial Earth Australia](../Beginners_guide/02_DEA.ipynb) section for more information on the surface reflectance corrections). Surface reflectance provides standardised optical datasets by using robust physical models to correct for variations in image radiance values due to atmospheric properties, as well as sun and sensor geometry. The resulting stack of surface reflectance grids are consistent over space and time, which is instrumental in identifying and quantifying environmental change.\n",
    "\n",
    "#### DEA provides two Sentinel-2 surface reflectance products:\n",
    "\n",
    "1. **Sentinel-2 Definitive** (e.g. `s2a_ard_granule`): These products represent the 'definitive' source of high quality Sentinel-2 surface reflectance data, and are available from the beginning of the Sentinel-2 archive up to a delay of several weeks. \n",
    "\n",
    "2. **Sentinel-2 Near Real Time** (e.g. `s2a_nrt_granule`): These products are processed with best-available ancillary information and provided as a rolling 90 day archive of imagery which is typically available to load within approximately ~24 hours of a satellite overpass.\n",
    "\n",
    "#### Both Sentinel-2 Definitive and Sentinel-2 Near Real Time products contain data processed to two surface reflectance corrections:\n",
    "\n",
    "1. **NBAR** (e.g. `nbar_green`): NBAR stands for Nadir-corrected BRDF Adjusted Reflectance, where BRDF stands for Bidirectional reflectance distribution function.\n",
    "    The approach involves atmospheric correction to compute surface-leaving radiance and bi-directional reflectance modelling to remove the effects of topography and angular variation in reflectance.\n",
    "\n",
    "2. **NBAR-T** (e.g. `nbart_green`): Surface reflectance NBAR-T includes the terrain illumination reflectance correction and has the same features of NBAR, along with some additional features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentinel-2 surface reflectance products have 13 spectral channels:\n",
    "\n",
    "| Sentinel-2 bands | DEA band name | Band number | Central wavelength (nm) | Resolution (m) | Bandwidth (nm) |\n",
    "| -----------------|---------------|-------------|-------------------------|----------------|----------------|\n",
    "| Coastal aerosol | `nbar(t)_coastal_aerosol` | 1 | 443 | 60 | 20 |\n",
    "| Blue | `nbar(t)_blue` | 2 | 490 | 10 | 65 |\n",
    "| Green | `nbar(t)_green` | 3 | 560 | 10 | 35 |\n",
    "| Red | `nbar(t)_red` | 4 | 665 | 10 | 30 |\n",
    "| Vegetation red edge | `nbar(t)_red_edge_1` | 5 | 705 | 20 | 15 |\n",
    "| Vegetation red edge | `nbar(t)_red_edge_2` | 6 | 740 | 20 | 15 |\n",
    "| Vegetation red edge | `nbar(t)_red_edge_3` | 7 | 783 | 20 | 20 |\n",
    "| NIR | `nbar(t)_nir_1` | 8 | 842 | 10 | 115 |\n",
    "| Narrow NIR | `nbar(t)_nir_2` | 8A | 865 | 20 | 20 |\n",
    "| Water vapour | N/A | 9 | 945 | 60 | 20 |\n",
    "| SWIR - Cirrus | N/A | 10 | 1375 | 60 | 20 |\n",
    "| SWIR | `nbar(t)_swir_2` | 11 | 1610 | 20 | 90 |\n",
    "| SWIR | `nbar(t)_swir_3` | 12 | 2190 | 20 | 180 |\n",
    "\n",
    "#### These bands cover the visible, near-infrared and short-wave infrared wave lengths.\n",
    "\n",
    "!['Sentinel-2 spectral bands'](http://www.geosage.com/highview/figures/Sentinel2_Spectral_Bands.jpg)\n",
    "     \n",
    "> **Note**: There are a number of additional datasets that are also returned as part of Sentinel-2 queries.\n",
    "These are a combination of datasets used in the correction process, and layers relating to pixel quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages and connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from odc.ui import with_ui_cbk\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.append(\"./Scripts\")\n",
    "from dea_datahandling import load_ard\n",
    "from dea_plotting import rgb\n",
    "from dea_plotting import display_map\n",
    "from datacube.utils.masking import make_mask\n",
    "\n",
    "dc = datacube.Datacube(app=\"Sentinel_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will load **Sentinel-2 Definitive** data from the Sentinel-2A and Sentinel-2B satellites using two methods. Firstly, we will use `dc.load()` to return a time series of satellite images from a single sensor. Secondly, we will load a time series using the `load_ard()` function, which is a wrapper function around the dc.load module. This function will load all the images from both Sentinel-2A and Sentinel-2B, combine them, and then apply a cloud mask. The returned `xarray.Dataset` will contain analysis ready images with the cloudy and invalid pixels masked out.\n",
    "\n",
    "#### You can change any of the parameters in the `query` object below to adjust the location, time, projection, or spatial resolution of the returned datasets.\n",
    "\n",
    "#### Sentinel-2 data is stored on file with a range of different coordinate reference systems or CRS (i.e. multiple UTM zones). The different satellite bands also have different resolutions (10 m, 20 m and 60 m).  Because of this, all Sentinel-2 queries need to include the following two query parameters:\n",
    "\n",
    "* `output_crs`: This sets a consistent CRS that all Sentinel-2 data will be reprojected to, regardless of the UTM zone the individual image is stored in.\n",
    "* `resolution`: This sets the resolution that all Sentinel-2 images will be resampled to. \n",
    "\n",
    "> Note: Be aware that setting `resolution` to the highest available resolution (i.e. `(-10, 10)`) will downsample the coarser resolution 20 m and 60 m bands, which may introduce unintended artefacts into your analysis.\n",
    "It is typically best practice to set `resolution` to match the lowest resolution band being analysed. For example, if your analysis uses both 10 m and 20 m resolution bands, set `\"resolution\": (-20, 20)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query object\n",
    "query = {\n",
    "    \"x\": (153.45, 153.47),\n",
    "    \"y\": (-28.90, -28.92),\n",
    "    \"time\": (\"2018-01\", \"2018-02\"),\n",
    "    \"output_crs\": \"EPSG:3577\",\n",
    "    \"resolution\": (-10, 10),\n",
    "    \"group_by\": \"solar_day\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The two **Sentinel-2 Definitive** products are:\n",
    "\n",
    "* `s2a_ard_granule`\n",
    "* `s2b_ard_granule`\n",
    "\n",
    ">Note: Here we will load in a time-series of satellite images from only Sentinel-2A. To load in images from Sentinel-2B, change the `product` variable to `'s2b_ard_granule'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dc.load(product=\"s2a_ard_granule\",\n",
    "             progress_cbk=with_ui_cbk(),\n",
    "             **query)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The returned dataset contains all of the bands available for Sentinel-2. These include both `NBAR` and `NBAR-T` versions of the optical bands, along with [fmask](../Frequently_used_code/Masking_data.ipynb) (used for cloud masking) and other measurements (e.g. `azimuthal_exiting`, `azimuthal_incident`) that are used for generating the surface reflectance product.\n",
    "\n",
    "#### Usually we are not interested in returning all the possible bands, but instead are only interested in a subset of these. If we wished to return only a few of `NBAR-T` optical bands, then we would pass a `measurements` parameter to `dc.load()` (or, alternatively, amend the initial `query` object to have a `measurements` parameter). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"nbart_blue\", \"nbart_green\", \"nbart_red\"]\n",
    "\n",
    "ds = dc.load(product=\"s2a_ard_granule\",\n",
    "             measurements=bands,\n",
    "             progress_cbk=with_ui_cbk(),\n",
    "             **query)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot the facetted contents of this Sentinel-2 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(ds, col=\"time\", col_wrap=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The often called agriculture RGB composite, uses bands SWIR-2, near-infrared and blue. Itâs mostly used to monitor crop health, as both short-wave and near infrared bands are particularly good at highlighting dense vegetation, which appears dark green in the composite. SWIR measurements can help scientists estimate how much water is present in plants and soil, as water reflects SWIR light. Shortwave-infrared bands are also useful for distinguishing between snow, and ice, all of which appear white in visible light. Newly burned land reflects strongly in SWIR bands, making them valuable for mapping fire damage.\n",
    "\n",
    "#### Exercise 5.1: Can you create an \"agriculture RGB composite of the previous images.\n",
    "\n",
    "> Tip: You might need to load new data specifying these bands. Remember that you can specify a `bands` parameter in the `rgb()` with the list of bands to map to the RGB channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ?\n",
    "\n",
    "rgb(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentinel-2 ARD contains a variable called `fmask` with information relative to pixel quality. The `fmask` variable contains values from 0 to 5, using a similar encoding to Landsat.\n",
    "\n",
    "| Value | Description |\n",
    "|-------|-------------|\n",
    "| 0 | Null |\n",
    "| 1 | Valid |\n",
    "| 2 | Cloud |\n",
    "| 3 | Cloud shadow |\n",
    "| 4 | Snow |\n",
    "| 5 | Water |\n",
    "\n",
    "#### Exercise 5.2: Load a new Dataset adding the `fmask` variable to the one in the previous exercise. Can you choose an area containing a water body and use the values in `fmask` to filter anything that is not classified as water in the images?\n",
    "\n",
    "> Note: You can visualise the evolution of water bodies over a period of time. Would you know how to calculate the evolution of the surface or extent covered by water through time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatively to the previous method, DEA offers the `load_ard()` function to load Sentinel-2 data more conveniently. This function will load images from both Sentinel-2A and Sentinel-2B, concatenate and sort the observations by time, and apply cloud masking.\n",
    "\n",
    "#### For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"nbart_blue\", \"nbart_green\", \"nbart_red\"]\n",
    "\n",
    "ds = load_ard(dc=dc,\n",
    "              products=[\"s2a_ard_granule\", \"s2b_ard_granule\"],\n",
    "              measurements=bands,\n",
    "              **query)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(ds, col='time', col_wrap=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see in the previous images, cloud masking in Sentinel-2 is not as reliable as in Landsat data. Improving the quality of cloud masking is a work in progress and you'll see an alternative solution later in this notebook.\n",
    "\n",
    "#### Sentinel-2 Near Real Time (NRT): The surface reflectance processing workflow for Sentinel-2 Definitive products typically causes a delay before this data is available to load through the datacube.\n",
    "\n",
    "#### To address this delay, DEA also provides a Sentinel-2 Near Real Time product which is available to load as early as ~24 hours after a satellite observation is made. Near Real Time data is processed using best-available ancillary information to provide atmospheric corrections, and delivered as a rolling 90 day archive of imagery.\n",
    "\n",
    "#### The two Sentinel-2 NRT products are:\n",
    "\n",
    "* `s2a_nrt_granule`\n",
    "* `s2b_nrt_granule`\n",
    "\n",
    "#### We can load Sentinel-2 NRT using either `dc.load()` or `load_ard()` using the methods demonstrated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"x\": (153.45, 153.47),\n",
    "    \"y\": (-28.90, -28.92),\n",
    "    \"measurements\": [\"nbart_blue\", \"nbart_green\", \"nbart_red\"],\n",
    "    \"output_crs\": \"EPSG:3577\",\n",
    "    \"resolution\": (-10, 10),\n",
    "    \"group_by\": \"solar_day\",\n",
    "}\n",
    "\n",
    "ds = load_ard(dc=dc,\n",
    "              products=[\"s2a_nrt_granule\", \"s2b_nrt_granule\"],\n",
    "              mask_pixel_quality=False,\n",
    "              **query)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can now plot the most recently acquired Sentinel-2 image in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `index=-1` selects the final image in the dataset\n",
    "rgb(ds, index=-1, size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5.3: Try to get the most recent image available for the place you choose in Australia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5.4: Use the facetted plots to display the evolution of the selected area using the \"agriculture\" false colour representation.\n",
    "\n",
    "> Hint: It might help to choose a sunny agricultural region to visualise the evolution of crops during the past 3 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are now going to see how to remove clouds of Sentinel2 images and how to create cloud free composites by combining several images.\n",
    "\n",
    "#### We start by defining an area in Canberra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'y': (-35.28, -35.34),\n",
    "    'x': (149.12, 149.18),\n",
    "    'time': ('2018-01', '2018-03'),\n",
    "    'output_crs': 'EPSG:3577',\n",
    "    'resolution': (-20, 20)\n",
    "}\n",
    "\n",
    "display_map(x=query['x'], y=query['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now load data from both Sentinel 2A and 2B datasets. We perform separate queries and then concatenate the data into a single dataset by interleaving the times so they are ordered.\n",
    "\n",
    "> Note: This step can take several minutes to complete; please be patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Sentinel-2A and 2B data including fmask cloud masking band\n",
    "s2a_ds = dc.load(\n",
    "    product='s2a_ard_granule',\n",
    "    measurements=['fmask', 'nbart_red', 'nbart_green', 'nbart_blue'],\n",
    "    progress_cbk=with_ui_cbk(),\n",
    "    **query)\n",
    "\n",
    "s2b_ds = dc.load(\n",
    "    product='s2b_ard_granule',\n",
    "    measurements=['fmask', 'nbart_red', 'nbart_green', 'nbart_blue'],\n",
    "    progress_cbk=with_ui_cbk(),\n",
    "    **query)\n",
    "\n",
    "# Combine Sentinel-2A and 2B data into a single dataset\n",
    "s2_ds = xr.concat([s2a_ds, s2b_ds], dim='time').sortby('time')\n",
    "\n",
    "s2_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's have a look at the RGB images in the resulting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(s2_ds, col='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can use XArray built-in functionality to create an average image along the time dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mean composite\n",
    "s2_mean = s2_ds.mean(dim='time')\n",
    "\n",
    "# Plot in RGB\n",
    "rgb(s2_mean, size=10)\n",
    "plt.title('Temporal mean of the image', fontdict={'fontsize': 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see the clouds are visible in this mean image. We are now going to remove this clouds using the `fmask` variable, which is included in the data that we have loaded. Let's have a look at the values that it contains and their interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_ds.fmask.flags_definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now use these variable to filter the cloud pixels in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify pixels that are either \"valid\", \"water\" or \"snow\"\n",
    "cloud_free_mask = (make_mask(s2_ds.fmask, fmask=\"valid\") |\n",
    "                   make_mask(s2_ds.fmask, fmask=\"water\") |\n",
    "                   make_mask(s2_ds.fmask, fmask=\"snow\"))\n",
    "\n",
    "# Apply mask to RGB bands\n",
    "s2_masked = s2_ds[['nbart_red', 'nbart_green',\n",
    "                   'nbart_blue']].where(cloud_free_mask)\n",
    "\n",
    "# Generate mean composite\n",
    "s2_mean = s2_masked.mean(dim='time')\n",
    "\n",
    "# Plot in RGB\n",
    "rgb(s2_mean, size=10)\n",
    "_ = plt.title('Masking with fmask', fontdict={'fontsize': 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unfortunately, as you can see, the `fmask` product does not work very well for Sentinel2 images. As an alternative, there is a better solution with the TSMask product.\n",
    "\n",
    "#### `TSmask` is a time series cloud and cloud shadow detection algorithm for Sentinel-2 surface reflectance data.  `TSmask` models time series of surface reflectance derived indices and calculates time series abnormality coefficients for pixels in the time series. `TSmask` does not rely on predefined training data to generate complex models with many rule sets, which often work well for data similar to the training data while return poor results for data contrasting to the training data. Instead, `TSmask` identifies cloud and cloud shadows by detecting local abnormalities in temporal and spatial contexts from abnormality coefficients.\n",
    "\n",
    "#### The `TSmask` analysis algorithm classifies each Sentinel-2 pixel into one of four distinctive categories:\n",
    "\n",
    "* 0 = No observation\n",
    "* 1 = Clear\n",
    "* 2 = Cloud\n",
    "* 3 = Cloud shadow\n",
    "\n",
    "#### `TSmask` is available in DEA in a product called `s2_tsmask`. We can inspect its features using `dc.list_measurements()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.list_measurements().loc['s2_tsmask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlike Sentinel 2 ARD data which is provided in seperate products for Sentinel-2A and 2B, the `s2_tsmask` product is provided as a single dataset that includes classifications for both Sentinel-2A and 2B. Let's load this product using the same query details that used to request the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in temporal cloudmask data\n",
    "tsmask_ds = dc.load(product='s2_tsmask', \n",
    "                    progress_cbk=with_ui_cbk(),\n",
    "                    **query)\n",
    "\n",
    "tsmask_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset has a single varible called `classification`, which contains the cloud and cloud shadow masking data.\n",
    "\n",
    "#### The `classification` band contains flag information that classifies each pixel into no data, valid, cloudy and cloud shadowed observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsmask_ds.classification.flags_definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to differences in the processing pipelines used to generate Sentinel-2 ARD data and `TSmask`, there may be a different number of observations returned for both of these datasets. The following step can be useful for ensuring that both datasets contain exactly the same observations:\n",
    "\n",
    "```\n",
    "matching_times = (tsmask_ds.time - s2_ds.time).time\n",
    "tsmask_ds = tsmask_ds.sel(time=matching_times)\n",
    "s2_ds = s2_ds.sel(time=matching_times)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can plot the same data with a mask generated from `TSmask` applied instead of `fmask`. Note that compared to the example above, the composite is clean and free of cloud or shadow, indicating that classification did a better job of removing these sources of noise from the time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify pixels that are \"Clear\"\n",
    "cloud_free_mask = make_mask(tsmask_ds.classification, classification=\"valid\")\n",
    "\n",
    "# Apply mask to RGB bands\n",
    "s2_masked = s2_ds[['nbart_red', 'nbart_green',\n",
    "                   'nbart_blue']].where(cloud_free_mask)\n",
    "\n",
    "# Generate mean composite\n",
    "s2_mean = s2_masked.mean(dim='time')\n",
    "\n",
    "# Plot in RGB\n",
    "rgb(s2_mean, size=10)\n",
    "plt.title('Masking with TSmask', fontdict={'fontsize': 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5.5: Similarly to the previous example. Can you create an averaged image for a city in Australia using the TSmask product.\n",
    "\n",
    "> Note: Cloud masking is particularly tricky in cities, where certain rooftops present high reflectance values and are often missclassified by cloud detection algorithms. Persistence of high reflectance values over a time series allows to differentiate clouds from high reflectance surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use as many cells as you need\n",
    "\n",
    "query = {?}\n",
    "\n",
    "# Load in temporal cloudmask data\n",
    "tsmask_ds = dc.load(product='s2_tsmask', \n",
    "                    progress_cbk=with_ui_cbk(),\n",
    "                    **query)\n",
    "\n",
    "# Load in Sentinel-2A and 2B data including fmask cloud masking band\n",
    "s2a_ds = dc.load(\n",
    "    product='s2a_ard_granule',\n",
    "    measurements=['fmask', 'nbart_red', 'nbart_green', 'nbart_blue'],\n",
    "    progress_cbk=with_ui_cbk(),\n",
    "    **query)\n",
    "\n",
    "s2b_ds = dc.load(\n",
    "    product='s2b_ard_granule',\n",
    "    measurements=['fmask', 'nbart_red', 'nbart_green', 'nbart_blue'],\n",
    "    progress_cbk=with_ui_cbk(),\n",
    "    **query)\n",
    "\n",
    "# Combine Sentinel-2A and 2B data into a single dataset\n",
    "s2_ds = xr.concat([s2a_ds, s2b_ds], dim='time').sortby('time')\n",
    "\n",
    "???\n",
    "???\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disclaimer: The original notebook for this tutorial has been taken from the Sandbox `Beginners_guide` folder. Refer to the conditions specified in the original notebook and for updated versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f74cbb870cf42b9baf468100b3f453f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "20657a6456c2411dad69a3042eab088d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2666f746421b4c39a8bb9262024f60ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_20657a6456c2411dad69a3042eab088d",
       "style": "IPY_MODEL_4a27a75565c94eb8a3c153b413f53045",
       "value": "FPS: 2.4"
      }
     },
     "2ad8697cf7ea4cd99ca6a596e3fa1bf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a825ce310877406895c790636104f295",
        "IPY_MODEL_d58f1611496a4c92a23eeb54dc7eb456"
       ],
       "layout": "IPY_MODEL_753c28e7e52445758591653b2b4fb6c6"
      }
     },
     "2da26c24de19488c81c2f18ca05e0dd2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "3aa3bd9828824d709f0381cca72ac671": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_44ce021275b0413eb53e759e5d54b502",
       "style": "IPY_MODEL_3b2f648b88bd4326879f7df94a4dd9e1",
       "value": "216 of 216"
      }
     },
     "3b2f648b88bd4326879f7df94a4dd9e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "44ce021275b0413eb53e759e5d54b502": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4a27a75565c94eb8a3c153b413f53045": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4de997e4370240bf8f4b3cf345d942c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_f22641c7cd594345905e99f596fc88d1",
       "style": "IPY_MODEL_9e94c5c47c0248fbb05514143d47106b",
       "value": "FPS: 7.0"
      }
     },
     "4e32d03ee9c84480a575dba9afc0bb99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "67e59e44fdd04722a20b9938a757b3ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "justify_content": "space-between"
      }
     },
     "7160e2d4e89143b880b42f47531c6a8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "753c28e7e52445758591653b2b4fb6c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "7ad178744b9549b0bcd73a5e426661c8": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "7d3e8bf9272444fc9cd96b608d8ad9d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "929545881c8f499bb427c51d058f795d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d543983a976e4425a9a5b9d6ac47675f"
       ],
       "layout": "IPY_MODEL_9f3293775d264e449ad179c0136015ec"
      }
     },
     "96a298f688a44f7b8981029a6ef4b870": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9e94c5c47c0248fbb05514143d47106b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9f3293775d264e449ad179c0136015ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9fa967ee06214d07a6f84a316e702302": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "layout": "IPY_MODEL_7160e2d4e89143b880b42f47531c6a8d",
       "max": 18,
       "style": "IPY_MODEL_e0b77d995d1d4e2691f38dff30bee4a3",
       "value": 18
      }
     },
     "a825ce310877406895c790636104f295": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4de997e4370240bf8f4b3cf345d942c1",
        "IPY_MODEL_b48629bf17984736ab0483564e447162"
       ],
       "layout": "IPY_MODEL_f130e071db0945139b44e39b1e6d1c3e"
      }
     },
     "b48629bf17984736ab0483564e447162": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_4e32d03ee9c84480a575dba9afc0bb99",
       "style": "IPY_MODEL_0f74cbb870cf42b9baf468100b3f453f",
       "value": "18 of 18"
      }
     },
     "bc9a3520912b4fec9334cf4275b05f54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "d543983a976e4425a9a5b9d6ac47675f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "layout": "IPY_MODEL_bc9a3520912b4fec9334cf4275b05f54",
       "max": 216,
       "style": "IPY_MODEL_7d3e8bf9272444fc9cd96b608d8ad9d5",
       "value": 216
      }
     },
     "d58f1611496a4c92a23eeb54dc7eb456": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9fa967ee06214d07a6f84a316e702302"
       ],
       "layout": "IPY_MODEL_96a298f688a44f7b8981029a6ef4b870"
      }
     },
     "e0b77d995d1d4e2691f38dff30bee4a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e1d92be453544e3a8d0435174f681727": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2666f746421b4c39a8bb9262024f60ab",
        "IPY_MODEL_3aa3bd9828824d709f0381cca72ac671"
       ],
       "layout": "IPY_MODEL_67e59e44fdd04722a20b9938a757b3ff"
      }
     },
     "e22f0af6da39410dbd0a13586c57e980": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e1d92be453544e3a8d0435174f681727",
        "IPY_MODEL_929545881c8f499bb427c51d058f795d"
       ],
       "layout": "IPY_MODEL_2da26c24de19488c81c2f18ca05e0dd2"
      }
     },
     "f130e071db0945139b44e39b1e6d1c3e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "justify_content": "space-between"
      }
     },
     "f22641c7cd594345905e99f596fc88d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fb95936178b9408ebe7da2889921b1e7": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
