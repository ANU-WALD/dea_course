{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Digital Earth Australia\n",
    "\n",
    "> This tutorial introduces the DEA Python library for working with 30 years of high resolution remote sensing data for Australia.\n",
    "\n",
    "- toc: false \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [dea]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Digital Earth Australia](https://www.ga.gov.au/dea) (DEA) is a digital platform that offer large amounts of Earth observation data that is ready to be analysed, covering continental Australia. DEA functionality is offered using a Python module, building on top and expanding the functionality that we have seen in Numpy, Matplotlib and XArray. To access the functionality of DEA we need to import the library. Then we declare a `Datacube` object that is going to be our point of access to the DEA data collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "\n",
    "dc = datacube.Datacube(app='welcome-to-dea')\n",
    "\n",
    "print(dc)\n",
    "print(\"---------------\")\n",
    "type(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digital Earth Australia offers a catalogue of data from a range of satellite sensors that offer the most recent images all the way back to 1986. The DEA data comes from the following satellites:\n",
    "\n",
    "* [Landsat 5 TM](https://www.usgs.gov/land-resources/nli/landsat/landsat-5?qt-science_support_page_related_con=0#qt-science_support_page_related_con) (LS5 TM), operational between March 1984 and January 2013\n",
    "* [Landsat 7 ETM+](https://www.usgs.gov/land-resources/nli/landsat/landsat-7?qt-science_support_page_related_con=0#qt-science_support_page_related_con) (LS7 ETM+), operational since April 1999\n",
    "* [Landsat 8 OLI](https://www.usgs.gov/land-resources/nli/landsat/landsat-8?qt-science_support_page_related_con=0#qt-science_support_page_related_con) (LS8 OLI), operational since February 2013\n",
    "* [Sentinel 2A MSI](https://sentinel.esa.int/web/sentinel/missions/sentinel-2) (S2A MSI), operational since June 2015\n",
    "* [Sentinel 2B MSI](https://sentinel.esa.int/web/sentinel/missions/sentinel-2) (S2B MSI, operational since March 2017\n",
    "\n",
    "#### Landsat missions are jointly operated by the United States Geological Survey (USGS) and National Aeronautics and Space Administration (NASA). Sentinel missions are operated by the European Space Agency (ESA). One major difference between the two programs is the spatial resolution: each Landsat pixel represents 30 x 30 m on the ground while each Sentinel-2 pixel represents 10 x 10 m to 60 x 60 m depending on the spectral band.\n",
    "\n",
    "![Image](https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/styles/full_width/public/thumbnails/image/dmidS2LS7Comparison.png)\n",
    "\n",
    "\n",
    "#### The `Datacube` object that we have created has functionality attached to it. For example, we can get a list of the products available by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.list_products().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: The `.head()` method in the previous cell limits the rown of the list to the first 10. You can try removing or commenting out this method using the `#` symbol to see the total number of rows although Jupyter will limit the size of the list. \n",
    "\n",
    "#### The [Sandbox Explorer](https://explorer.sandbox.dea.ga.gov.au/) is an online tool that documents the datasets available in the Sandbox environment. \n",
    "\n",
    "#### EPSG stands for European Petroleum Survey Group and this accronym commonly refers to the geodetic parameter database with standard codes for coordinate systems, datums, spheroids and units. This code is normally used to uniquely define the map projection used to generate a map. As you'll probably know there are different map projections with different characteristics, such as Mercator, Conic or Conformal.\n",
    "\n",
    "#### Exercise 8.1: Can you find the EPSG code that DEA uses to store its data collections. Youn migth need to scroll towards the right side of the table to locate this column. \n",
    "\n",
    "* **a)** EPSG:4326\n",
    "* **b)** EPSG:3577\n",
    "* **c)** EPSG:2360\n",
    "\n",
    "> Tip: If you are interested in knowing more about EPSG codes [here](https://spatialreference.org/) shows a full list of reference systems and descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from check_answer import check_answer\n",
    "\n",
    "# Substitute the ? symbols by either 'a', 'b' or 'c'\n",
    "answ = ?\n",
    "\n",
    "check_answer(\"8.1\", answ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digital Earth Australia produces Analysis Ready Data (ARD) for each of the sensors listed above. The [ARD standard](http://ceos.org/ard/) for satellite data requires that data have undergone a number of processing steps, along with the creation of additional attributes for the data. DEA's ARD datasets include the following characteristics:\n",
    "\n",
    "* **Geometric correction:** This includes establishing ground position, accounting for terrain (orthorectification) and ground control points, and assessing absolute position accuracy. \n",
    "Geometric calibration means that imagery is positioned accurately on the Earth's surface and stacked consistently so that sequential observations can be used to track meaningful change over time.\n",
    "Adjustments for ground variability typically use a Digital Elevation Model (DEM).\n",
    "* **Surface reflectance correction:** This includes adjustments for sensor/instrument gains, biases and offsets, include adjustments for terrain illumination and sensor viewing angle with respect to the pixel position on the surface.\n",
    "Once satellite data is processed to surface reflectance, pixel values from the same sensor can be compared consistently both spatially and over time.\n",
    "* **Observation attributes:** Per-pixel metadata such as quality flags and content attribution that enable users to make informed decisions about the suitability of the products for their use. For example, clouds, cloud shadows, missing data, saturation and water are common pixel level attributes.\n",
    "* **Metadata:** Dataset metadata including the satellite, instrument, acquisition date and time, spatial boundaries, pixel locations, mode, processing details, spectral or frequency response and grid projection.\n",
    "\n",
    "\n",
    "#### Optical sensors mounted on satellites measure the energy that comes from the sun and has been reflected by the Earth's surface. The sensor measures the energy in each of its spectral bands. There are many factors that affect the amount of energy that reaches the satellite sensor such as the solar and satellite angles relative to the surface and the atmospheric conditions. In order to analyse and compare images taken at different times, the data needs to be normalised into some standard conditions. Surface reflectance is one of this normalisations and is calculated using advanced physical models to correct the reflectance values taking into account atmospheric conditions, sun and satellite angles and local topography.\n",
    "\n",
    "#### DEA offers to options for adjusted or normalised surface reflectance:\n",
    "\n",
    "* **NBAR**: NBAR stands for *Nadir-corrected BRDF Adjusted Reflectance*, where BRDF stands for *Bidirectional reflectance distribution function*. The approach involves atmospheric correction to compute bottom-of-atmosphere radiance, and bi-directional reflectance modelling to remove the effects of topography and angular variation in reflectance. NBAR can be useful for analyses in extremely flat areas not affected by terrain shadow, and for producing attractive data visualisations that are not affected by NBART's nodata gaps (see below).\n",
    "\n",
    "* **NBART**: NBART has the same features of NBAR but includes an additional *terrain illumination* reflectance correction that takes into account the surface topography. Terrain affects optical satellite images in a number of ways; for example, slopes facing the sun receive more sunlight and appear brighter compared to those facing away from the sun. This correction is performed with a Digital Surface Model (DSM). NBART is typically the default choice for performing analysis that are consistent through time. However, it can be introduce distortion in flat areas due to the noise in DSM data.\n",
    "\n",
    "![Comparison between NBAR and NBART](data/nbar_nbart_animation.gif)\n",
    "\n",
    "#### The animation above demonstrates how the NBART correction results in a significantly more two-dimensional looking image that is less affected by terrain illumination and shadow. Black pixels in the NBART image represent areas of deep terrain shadow that can't be corrected as they're determined not to be viewable by either the sun or the satellite. These are represented by -999 `nodata` values in the data.\n",
    "\n",
    "> Note: Remember that remote sensing data is often stored as `uint16` to save space and `NaN` is only available for floating point types, that is why we need a value `-999` in this case to designate not-a-number data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8.2: In which cases can NBAR be preferred to NBART data?\n",
    "\n",
    "* **a)** When dealing with images with clouds and shadows affecting the surface reflectance values.\n",
    "* **b)** In areas with mountains and high relief to perform time-series analysis.\n",
    "* **c)** In flat regions when we want to minimise the occurrence of no-data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute the ? symbols by either 'a', 'b' or 'c'\n",
    "answ = ?\n",
    "\n",
    "check_answer(\"8.2\", answ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that know about the satellites and levels of processing in DEA, lets see how we can request some data.\n",
    "\n",
    "#### Requesting data is done in a natural way by providing information about:\n",
    "* What is the data collection that we want to request. **What**\n",
    "* What area or spatial extent we want our image to cover. **Where**\n",
    "* What is the time span we want to cover. **When**\n",
    "\n",
    "#### We now need to pass all this information to the `dc.load()` function. We normally use a dictionary to describe our request as in the following example:\n",
    "\n",
    ">Tip: See this website for a full documentation of this and other DEA API functions [dc.load()](https://datacube-core.readthedocs.io/en/latest/dev/api/generate/datacube.Datacube.load.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query={'lat': (-35.25, -35.35),\n",
    "       'lon': (149.05, 149.17),\n",
    "       'time':('2018-01-01', '2019-01-01')}\n",
    "\n",
    "ds = dc.load(product='ls8_nbart_geomedian_annual', **query)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Tip: DEA uses XArray as its underlying data model and defines a simple querying interface to select satellite data which returns as `Dataset` objects.\n",
    "\n",
    "#### We can use the plotting functionality in XArray to generate a true colour image of this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[['red', 'green', 'blue']].isel(time=0).to_array().plot.imshow(robust=True, figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.red.isel(time=0).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8.3: Can you create a false colour representation of the previous image mapping the red channel in the image to the `nir` variable and keeping the rest of the channels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answ = ?\n",
    "\n",
    "ds[answ].isel(time=0).to_array().plot.imshow(robust=True, figsize=(6,6))\n",
    "\n",
    "check_answer(\"8.3\", answ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The *Observation Attributes (OA)* are a suite of measurements included in DEA's analysis ready datasets. They provide individual information for each pixel in an image to determine its quality. The OA product allows users to exclude pixels that do not meet the quality criteria for their analysis. The capacity to detect such pixels is essential for analysing changes over time, since poor-quality pixels (due to clouds or saturations) can significantly alter the percieved changes over time. The most common use of OA is for cloud masking, where users can choose to remove images that have too much clouds, or ignore the clouds within each satellite image. \n",
    "\n",
    "#### The OA suite of measurements include the following observation pixel-based attributes:\n",
    "\n",
    "* Null pixels\n",
    "* Clear pixels\n",
    "* Cloud pixels\n",
    "* Cloud shadow pixels\n",
    "* Snow pixels\n",
    "* Water pixels\n",
    "* Terrain shaded pixels\n",
    "* Spectrally contiguous pixels (i.e. whether a pixel contains data in every spectral band)\n",
    "\n",
    "#### Also included is a range of pixel-based attributes related to the satellite, solar and sensing geometries:\n",
    "\n",
    "* Solar zenith\n",
    "* Solar azimuth\n",
    "* Satellite view\n",
    "* Incident angle\n",
    "* Exiting angle\n",
    "* Azimuthal incident\n",
    "* Azimuthal exiting\n",
    "* Relative azimuth\n",
    "* Timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8.4: Which of the following features is **not** part of the OA data?\n",
    "\n",
    "* **a)** Water pixel\n",
    "* **b)** Terrain shaded pixel\n",
    "* **c)** Vegetation pixel\n",
    "* **d)** Missing data in any spectral band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute the ? symbols by either 'a', 'b', 'c' or 'd'\n",
    "answ = ?\n",
    "\n",
    "check_answer(\"8.4\", answ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8.5: Using the same `ls8_nbart_geomedian_annual` collection as the previous example, can you plot an image of any place you want in Australia?\n",
    "\n",
    ">Tip: Be careful with the extents in your request. Cubes with sizes 0.1 degree are easily managed by the Sandbox but you can quickly run out of memory if you increase the extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query={'lat': (?, ?),\n",
    "         'lon': (?, ?),\n",
    "         'time':('2010-01-01', '2019-01-15')}\n",
    "\n",
    "ds = dc.load(product='ls8_nbart_geomedian_annual', **query)\n",
    "\n",
    "ds[['red', 'green', 'blue']].isel(time=0).to_array().plot.imshow(robust=True, figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8.6: Now that you are able to request remote sensing data from anywhere in Australia, we are going to wrap up the day applying some of the things we have learned to the image that you have generated. Go through the following cells performing the operations and analysis on the XArray containing the geomedian data that you have just created.\n",
    "\n",
    "#### 1.- Can you find the data type of these data as well as the minimum and maximum values in the red band?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.- Select the most recent time in the red band and access the underlying numpy array.\n",
    "\n",
    "> Tip: Make sure `.shape` returns a 2-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.- Transform this array into type `uint8` with values ranging from [0-255].\n",
    "\n",
    "> Tip: You will need to strectch the initial values in the array so the minimum value is mapped to `0` and the maximum value corresponds to `255`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.- Use Matplotlib to create an image representation of this array using the colormap called `jet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.- Perform the same operation to the green and blue channels (type conversion and value stretching) and stack them into a 3-dimensional array where the colour channels are placed in the last dimension.\n",
    "\n",
    "> Tip: Remember `np.dstack()` stacks 2-dimensional arrays over the 3rd axis and `np.stack()` is the generic numpy function to stack arrays over any axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.- Use Matplotlib to create a RGB representation of the previous image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.- Coming back to the origal `Dataset`. Can you create a mask that is True for the values in the red band that have values less than 5000?\n",
    "\n",
    "> Tip: Select any time in the original Dataset to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.- How many values are False in your mask? What is the percentage of False values over the total size of the image? Reduce the previous value if you get 0 or a low value.\n",
    "\n",
    "> Tip: You can use the numpy.count_nonzero() function to count the number of True values in an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.- Save the contents of the red band for the selected time into a numpy array and use the previous mask to set the values greater than your threshold to `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.- What is the mean and standard deviation values of the remaining values in your array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
